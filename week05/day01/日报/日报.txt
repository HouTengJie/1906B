2020-06-01：
一、ElasticSearch介绍
   1、什么是elasticsearch?
ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个基于RESTful web接口的分布式全文搜索引擎。ElasticSearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。ElasticSearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。根据DB-Engines的排名显示，ElasticSearch是最受欢迎的企业搜索引擎，其次是Apache Solr（也是基Lucene）。
总结：
​ 1、elasticsearch是一个基于Lucene的分布式全文检索服务器。
​ 2、elasticsearch隐藏了Lucene的复杂性，对外提供Restful 接口来操作索引、搜索。
es和solr选择哪个？
1.如果你公司现在用的solr可以满足需求就不要换了。
2.如果你公司准备进行全文检索项目的开发，建议优先考虑elasticsearch，因为像Github这样大规模的搜索都在用它。


2、elasticsearch原理
索引结构
​ 下图是ElasticSearch的索引结构，右边黑蓝色色部分是原始文档，左边黄色部分是逻辑结构，逻辑结构也是为了更好的去描述ElasticSearch的工作原理及去使用物理结构中的索引文件。

倒排索引
倒排索引（Inverted index）:也常被称为反向索引，倒排索引是从关键字到文档的映射（已知关键字求文档）。
逻辑结构部分是一个倒排索引表，由三部分组成：
1、将搜索的文档最终以<font color=red>Document</font>方式存储起来。
2、将要搜索的文档内容分词，所有不重复的词组成<font color=red>分词</font>列表。
3、每个分词和docment都有<font color=red>关联</font>。



现在，如果我们想搜索 包含quick brown词条的文档：

两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。

二、ES安装
环境需求
1、jdk必须是jdk1.8.0_131以上版本。
2、ElasticSearch 需要至少4096 的线程池才能正常启动，ES 至少需要 65536 的文件创建权限，所以需要为虚拟机分配至少1.5G以上的内存
3、从5.0开始，ElasticSearch 安全级别提高了，不允许采用root帐号启动
4、Elasticsearch的插件要求至少3.5以上版本
	a、安装
		1、设置虚拟机内存>1.5G
		2、创建用户
		3、安装
			解压即安装
			配置elasticsearch.yml
		4、解决内核问题
		5、解决文件创建权限问题
		6、决绝线程开启限制问题
		7、解决虚拟机内存问题

	b、启动和关闭
		启动：
			./bin/elasticsearch
			./elasticsearch -d

		关闭：			kill -9 pid



2020-06-02：
三、ES快速入门
 1、index管理
1.创建index
索引：包含若干相似结构的 Document 数据，相当于数据库的database。
语法：

PUT /java1906
{
  "settings": {
    "number_of_shards": 2,
    "number_of_replicas": 0
  }
}
number_of_shards - 是表示一个索引库将拆分成多片分别存储不同的结点，提高了ES的处理能力和高可用性
number_of_replicas- 是为每个 primary shard分配的replica shard数，如果只有一台机器，设置为0

2.修改index
注意：索引一旦创建，primary shard 数量不可变化，可以改变replica shard 数量。

PUT /java1906/_settings
{
  "number_of_replicas" : 1
}
ES 中对 shard 的分布是有要求的，有其内置的特殊算法：
​ Replica shard 会保证不和他的那个 primary shard 分配在同一个节点上；如过只有一个节点，则此案例执行后索引的状态一定是yellow。
3.删除index
DELETE /java1906 [, other_index]
2.mapping管理
映射，创建映射就是向索引库中创建field（类型、是否索引、是否存储等特性）的过程，下边是document和field与关系数据库的概念的类比：
​ 索引库（index）--------------------------------Database数据库
​ 类型（type）-----------------------------Table数据表
​ 文档（Document）----------------Row 行
​ 字段（Field）-------------------Columns 列
注意：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES6.x 版本之后，type概念被弱化ES官方将在ES7.0版本中彻底删除type。

1.创建mapping
语法：POST index_name/type_name/_mapping
如：

POST /java1906/course/_mapping
{
  "properties": {
     "name": {
        "type": "text"
     },
     "description": {
        "type": "text"
     },
     "studymodel": {
        "type": "keyword"
     }
  }
}
2.查询mapping
查询所有索引的映射：

GET /java1906/course/_mapping

3、doucument管理
a、创建doucment
		POST /java1907/couse/1
		{
			"name":"php从入门到放弃"
		}
		POST /java1907/couse
		{
			"name":"php从入门到放弃"
		}
		PUT /java1907/couse/1
		{
			"name":"php从入门到放弃"
		}
b、查询doucument
		如：根据课程id查询文档
GET /java1906/course/1
如：查询所有记录
GET /java1906/course/_search
如：查询名称中包括php 关键字的的记录
GET /java1906/course/_search?q=name:门

	c、删除document
		DELETE /java1906/couse/1

四、IK分词器
  1、安装
	解压到plugs目录下，并重命名为ik

    2、自定义词库
	IkAnalyzer.cfg.xml：配置扩展词典和停用词典
	main.dic：扩展词典
	stopwords.dic：停用词典

3、两种分词模式
ik分词器有两种分词模式：ik_max_word和ik_smart模式。
1、ik_max_word
​ 会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人		民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、		会堂等词语。
2、ik_smart
​ 会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和		国、人民大会堂。
五、field详细介绍
1.field的属性介绍
1.type：
通过type属性指定field的类型。

"name":{
       "type":"text"
}
2.analyzer：
通过analyzer属性指定分词模式。
 "name": {
               "type": "text",
               "analyzer":"ik_max_word"
   }
上边指定了analyzer是指在索引和搜索都使用ik_max_word，如果单独想定义搜索时使用的分词器则可以通过search_analyzer属性。对于ik分词器建议是索引时使用ik_max_word将搜索内容进行细粒度分词，搜索时使用ik_smart提高搜索精确性。

"name": {
                  "type": "text",
                  "analyzer":"ik_max_word",
                  "search_analyzer":"ik_smart"
 }
3.index：
通过index属性指定是否索引。默认为index=true，即要进行索引，只有进行索引才可以从索引库搜索到。但是也有一些内容不需要索引，比如：商品图片地址只被用来展示图片，不进行搜索图片，此时可以将index设置为false。 删除索引，重新创建映射，将pic的index设置为false，尝试根据pic去搜索，结果搜索不到数据
"pic": {
       "type":"text",          
       "index":false
}
2.field索引不存储
​ 如果某个字段内容非常多，业务里面只需要能对该字段进行搜索，比如：商品描述。查看文档内容会再次到mysql或者hbase中取数据，把大字段的内容存在Elasticsearch中只会增大索引，这一点文档数量越大结果越明显，如果一条文档节省几KB，放大到亿万级的量结果也是非常可观的。
如果只想存储某几个字段的原始值到Elasticsearch，可以通过incudes参数来设置，在mapping中的设置如下:
POST /java1906/course/_mapping
{
  "_source": {
    "includes":["description"]
  }
}
同样，可以通过excludes参数排除某些字段：
POST /java1906/course/_mapping
{
  "_source": {
    "excludes":["description"]
  }
}
4.常用field类型
1.text文本字段
例如：1、创建新映射：

POST /java1906/course/_mapping
{
  "properties": {  
       "name": {
           "type": "text",
           "analyzer":"ik_max_word",
           "search_analyzer":"ik_smart"
       },        
      "description": {
          "type": "text",
          "analyzer":"ik_max_word",
          "search_analyzer":"ik_smart"
      },
      "pic":{
          "type":"text",
          "index":false
      },
      "studymodel":{
          "type":"text"
      }
  }  
}
2、插入文档：

POST /java1906/course/1
{
  "name":"python从入门到放弃",
  "description":"人生苦短，我用Python",
  "pic":"250.jpg",
  "studymodel":"201002"
}
3.查询测试：

GET /java1906/course/_search?q=name:放弃
GET /java1906/course/_search?q= description:人生
GET /java1906/course /_search?q=pic:250.jpg
结果：name和description都支持全文检索，pic不可作为查询条件
4.keyword关键字字段
上边介绍的text文本字段在映射时要设置分词器，keyword字段为关键字字段，通常搜索keyword是按照整体搜索，所以创建keyword字段的索引时是不进行分词的，比如：邮政编码、手机号码、身份证等。keyword字段通常用于过虑、排序、聚合等。
1、更改映射：

POST /java1906/course/_mapping
{
    "properties": {
       "studymodel":{
          "type":"keyword"
       },
       "description": {
          "type": "text",
          "analyzer":"ik_max_word",
          "search_analyzer":"ik_smart"
       },
       "pic":{
         "type":"text",
         "index":false
       },
       "name":{
          "type":"keyword"
       }
    }
}
2、插入文档：
PUT /java1906/course/2
{
 "name": "java编程基础",
 "description": "java语言是世界第一编程语言",
 "pic":"250.jpg",
 "studymodel": "201001"
}
3、根据name查询文档：
GET /java1906/course/_search?q=name:java编程基础
name是keyword类型，所以查询方式是精确查询。
5.date日期类型
日期类型不用设置分词器，通常日期类型的字段用于排序。1)format通过format设置日期格式，多个格式使用双竖线||分隔, 每个格式都会被依次尝试, 直到找到匹配的
1、设置允许date字段存储年月日时分秒、年月日及毫秒三种格式。
POST /java1906/course/_mapping
{
    "properties": {
       "timestamp": {
         "type":   "date",
         "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd"
       }
     }
}
2、插入文档：
PUT /java1906/course/3
{
"name": "spring开发基础",
"description": "spring 在java领域非常流行，java程序员都在用。",
"studymodel": "201001",
 "pic":"250.jpg",
 "timestamp":"2018-07-04 18:28:58"
}
6.Numeric类型
下图是ES支持的数值类型：尽可能选择范围小的数据类型,字段的长度越短, 索引和搜索的效率越高;

1、更新已有映射：
POST /java1906/course/_mapping
{
    "properties": {
    "price": {
        "type": "double"
     }
  }
}
2、插入文档
PUT /java1906/course/3
{
 "name": "spring开发基础",
 "description": "spring 在java领域非常流行，java程序员都在用。",
 "studymodel": "201001",
 "pic":"250.jpg",
 "timestamp":"2018-07-04 18:28:58",
 "price":38.6
}


2020-06-03：
六、Spring Boot整合ElasticSearch
1.搭建工程
1.pom.xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.1.6.RELEASE</version>
    </parent>

    <groupId>com.usian</groupId>
    <artifactId>springboot_elasticsearch</artifactId>
    <version>1.0-SNAPSHOT</version>
    <properties>
        <java.version>1.8</java.version>
    </properties>
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>elasticsearch-rest-high-level-client</artifactId>
        </dependency>
        <dependency>
            <groupId>org.elasticsearch</groupId>
            <artifactId>elasticsearch</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
        </dependency>
    </dependencies>
</project>
2.application.yml
spring:
  data:
    elasticsearch:
      cluster-nodes: 192.168.233.134:9200
3.Config
package com.usian.config;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class ElasticsearchConfig extends ElasticsearchProperties{

	@Bean
	public RestHighLevelClient getRestHighLevelClient() {
        String[] hosts = getClusterNodes().split(",");
        HttpHost[] httpHosts = new HttpHost[hosts.length];
        for (int i = 0; i < httpHosts.length; i++) {
            String h = hosts[i];
            httpHosts[i] = new HttpHost(h.split(":")[0],Integer.parseInt(h.split(":")[1]));
        }
		return new RestHighLevelClient(RestClient.builder(httpHosts));
	}
4.app
package com.usian;
​
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
​
@SpringBootApplication
public class ElasticsearchApp {
​
    public static void main(String[] args) {
        SpringApplication.run(ElasticsearchApp.class, args);
    }
}
2.索引管理
1.创建索引库
	CreateIndexRequest createIndexRequest = new CreateIndexRequest("java1906");
	createIndexRequest.settings("");
	createIndexRequest.mapping("");
	restHighLevelClient.indices().create(createIndexRequest,RequestOptions.DEFAULT)


2.删除索引库
	DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest("java1906");
	restHighLevelClient.indices().delete(deleteIndexRequest,RequestOptions.DEFAULT);

3.添加文档
	IndexRequest indexRequest = new IndexRequest("java1906", "course", "1");
	indexRequest.source();
	restHighLevelClient.index(indexRequest,RequestOptions.DEFAULT);

4.批量添加文档
	BulkRequest bulkRequest = new BulkRequest();
	bulkRequest.add(new IndexRequest("java1906", "course", "1").source(""));
	bulkRequest.add(new IndexRequest("java1906", "course", "1").source(""));
	restHighLevelClient.bulk(bulkRequest,RequestOptions.DEFAULT);

5.修改文档
	UpdateRequest updateRequest = new UpdateRequest("java1906", "course", "1");
	indexRequest.doc("");
	restHighLevelClient.update(indexRequest,RequestOptions.DEFAULT);

6.删除文档
	DeleteRequest deleteRequest = new DeleteRequest("java1906", "course", "1");
	restHighLevelClient.delete(deleteRequest,RequestOptions.DEFAULT);

7.简单搜索
	GetRequest getRequest = new GetRequest("java1906", "course", "1");
	restHighLevelClient.get(getRequest,RequestOptions.DEFAULT);

8.dsl搜索
	1、match_all
		SearchRequest searchRequest = new SearchRequest("java1906");
		searchRequest.types("course");

		SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
		searchSourceBuilder.query(QueryBuilders.matchAllQuery());

		searchRequest.search(searchSourceBuilder)
		restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);

	2、分页查询
		SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
		searchSourceBuilder.query(QueryBuilders.matchAllQuery());
		searchSourceBuilder.form(1);
		searchSourceBuilder.size(2);
		searchSourceBuilder.sort("price",SortOrder.DESC);
2020-06-05
   商品搜索：
           搜索展示的商品信息：
               对应的业务域：
              	   1、商品Id  2、商品标题  3、商品卖点  4、商品价格  5、商品图片  6、分类名称  7、商品描述
               需要从tb_item, tb_item_cat, tb_item_desc表中查询商品数据：
               根据前端传过来的搜索条件，到后台进行查询，名字，描述，卖点，类别，这些域，同时进行数据分页和搜索条件的
           高亮处理，最后返回一个结果集，完成查询

   索引库同步：
	   索引库同步，这个索引库同步是使用MQ实现的,MQ的主要作用有，应用解耦，流量削锋，异步处理。在商品添加的
              时候，将添加的数据ID发送到MQ中，然后在ElasticSearch模块的服务消费者，配置MQ的队列监听，收到消息后，
              通过ID去数据库中查询信息，并添加到ElasticSearch中，实现索引库同步


2020-06-08
1.商品详情的方案

1.1.网页静态化方案

1、创建商品详情的thymeleaf模板

2、创建一个RabbitMQ的消费者，收到消息后创建静态页面

3、搭建nginx服务器，返回静态页面

1.2.redis缓存商品信息方案

使用redis做缓存，业务逻辑：

1、根据商品id到redis中查询,查得到，直接返回

2、查不到，查询mysql, 数据放到redis中设置缓存的有效期一天的时间，可以根据实际情况调整。

需要使用String类型来保存商品数据，可以加前缀对redis中的key进行归类：

ITEM_INFO:123456:BASE

ITEM_INFO:123456:DESC

ITEM_INFO:123456:PARAM

2.查询商品详情

2.1.创建usian_detail_web
2.2.查询商品信息
4.缓存穿透
3.1.描述
缓存穿透是指缓存和数据库中都没有数据，而用户不断发起请求则这些请求会穿过缓存直接访问数据库，
如发起为id为“-1”的数据或id为特别大不存在的数据。假如有恶意攻击，就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。
3.2.解决方案
缓存空对象：
当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间（避免控制占用更多的存储空间），
之后再访问这个数据将会从缓存中获取，保护了后端数据源；

4缓存击穿
4.1.描述

缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个key不停进行访问，
当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

2020-06-09:
1.单点登录介绍
1.1.什么是单点登录
SSO英文全称Single Sign On，单点登录。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统，
例如：【百度：百度文库、百度外卖】、【淘宝：淘宝、天猫】、【优思安：门户、搜索、商品详情】。
它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一。

1.2.为什么要有单点登录系统
集群环境下会出现要求用户多次登录的情况。
解决方案：
1、配置tomcat集群(500)。配置tomcat Session复制。节点数不要超过5个。

2、可以使用Session服务器（sso系统），保存Session信息。需要模拟Session。

session和redis的共同特点：

1、kv形式存储

2、过期时间

单点登录系统是使用redis模拟Session，实现Session的统一管理。

1.3.需求分析

1.3.1.登录

把用户信息装到redis(token，user)，再把token装到cookie(token_key,token)

1.3.2.查询

先从cookie中取出token，再通过token从redis中查询用户信息

2.工程搭建

2.1.创建usian_sso_service

2.1.1.创建工程
2.1.2.pom.xml
2.1.3.application.yml
2.1.4.logback.xml
2.1.5.创建启动类

2.2.创建usian_sso_feign
2.2.1.创建工程
2.2.2.pom.xml

2.3.创建usian_sso_web
2.3.1.创建工程
2.3.2.pom.xml
2.3.3.application.yml
2.3.4.logback.xml
2.3.5.创建启动类

2.注册信息校验
2.1.usian_sso_service
2.1.1.service
2.1.2.controller

2.2.usian_sso_feign
2.2.1.feign

2.3.usian_sso_web
2.3.1.controller

3.用户注册
3.1.usian_sso_service
3.1.1.service
3.1.2.controller

3.2.usian_sso_feign
3.2.1.feign

3.3.usian_sso_web
3.3.1.controller

4.用户登录
4.1.usian_sso_service
4.1.1.service
4.1.2.controller

4.2.usian_sso_feign
4.2.1.feign

4.3.usian_sso_web
4.3.1.controller

4.4.测试
1、观察cookie
2、测试是否显示登录用户名

5.通过token查询用户信息
5.1.业务逻辑
1、从url中取参数token
2、根据token查询redis
3、如果查询不到数据，前台删除cookie中的用户信息
4、如果查询到数据，说明用户已经登录需要重置key的过期时间

5.2.usian_sso_service
5.2.1.service
5.2.2.controller

5.3.usian_sso_feign
5.3.1.feign

5.4.usian_sso_web
5.4.1.controller

5.5.测试
测试是否显示登录用户名

6.退出登录
6.1.usian_sso_service
6.1.1.service
6.1.2.controller

6.2.usian_sso_feign
6.2.1.feign

6.3.usian_sso_web
6.3.1.controller
6.4.测试
2020-06-10
1.购物车设计
1. 用户未登录状态下：在不登陆的情况下把购物车信息写入cookie
   	优点：
   		1、不占用服务端存储空间
   		2、代码实现简单。
   		3、用户体验好
   	缺点：
   		1、cookie中保存的容量有限。最大4k
   		2、把购物车信息保存在cookie中，更换设备购物车信息不能同步。
2. 用户已登录状态下：把购物车信息保存到服务端的 Redis 中
   	优点：
   		1、更换设备购物车信息可以同步
   	缺点：
   		1、占用服务端存储空间
2.未登录状态操作购物车

2.1.业务逻辑：

1、从cookie中查询商品列表：Map<itemId,TbItem> 商品购买数量使用TbItem的num保存

	    购物车已存在则直接返回

        购物车不存在则创建空的购物车并返回

2、添加商品到购物车：

	如果购物车存在该商品，商品数量相加。

	如果购物车不存在该商品，根据商品id查询商品信息并添加到购车列表

3、把购车商品列表写入cookie。

	读写cookie可以使用CookieUtils工具类实现
2020-06-16
1.1.订单功能

1、在购物车页面点击“去结算”按钮跳转到订单确认页面

	a) 展示商品列表

	b) 配送地址列表

    c) 选择支付方式

2、订单确认页面需要根据用户查询配送地址，展示订单确认页面之前，应该确认用户身份

	a) 如果用户未登录或登录过期跳转到登录页面

	d) 登录成功后再跳转到订单确认页面

3、提交订单

	a) 生成订单

4、扣减库存

5、关闭超时订单

	a) 定时扫描超时2天未付款的订单，并关闭订单

	b) 加回库存
2.用户身份认证

在展示订单确认页面之前，需要对用户身份进行认证，要求用户必须登录。

2.1.功能分析

1、使用springmvc的拦截器拦截所有订单的请求

2、业务逻辑

	a)  从cookie中取token。

	b) 根据token调用sso服务查询用户信息。

	d) 如果查不到用户信息则跳转到登录页面。

	e) 查询到用户信息放行。
3.展示订单确认页面

3.1.功能分析

1、在购物车页面点击“去结算”按钮跳转到订单确认页面。

2、请求的url：/frontend/order/goSettlement

3、参数：ids，userId，token

4、查询redis中的购物车数据并返回给前端

5、配送地址列表，需要用户登录。需要根据用户id查询收货地址列表。静态数据。

6、支付方式。静态数据。
2020-06-17
1、保存订单信息
	a、在订单确认页面点击“提交订单”按钮生成订单。

	b、请求的url：/frontend/order/insertOrder

	c、参数：订单、订单商品、订单物流

	d、返回值：{"status":200,"msg":"OK","data":"订单ID"}
4.扣减库存
4.1.分析
将消息写入消息队列，业务逻辑以异步的方式运行，加快响应速度
2020-06-18
5.关闭超时订单
5.1分析
1、定义job扫描订单表：
        	 a、修改订单的状态为关闭状态、结束时间、关闭时间、修改时间为当前时间
		     b、把订单中商品的库存数量加回去
     		扫描条件：状态是未付款 并且 创建时间 <= 当前时间 – 2天  并且付款方式为在线支付的订单
2、  定义触发条件
		a)  理论上需要实时触发（性能问题）
		b)  1分钟触发一次 0 */1 * * * ?
6.quartz集群任务重复执行问题
6.1.分析
quartz 在集群的时候，任务会出现重复执行的情况：
6.2.quartz
使用redis分布式锁解决quartz 集群任务重复执行的问题
2020-06-18
1.事务的介绍

1.1.什么是事务？

当你需要一次执行多条SQL语句时，可以使用事务。通俗一点说，如果这几条SQL语句全部执行成功，则才对数据库进行一次更新，如果有一条SQL语句执行失败，则这几条SQL语句全部不进行执行，这个时候需要用到事务。

<font color=red>刘德华《无间道》：去不了终点，回到原点</font>

回顾一下数据库事务的四大特性ACID：

    原子性（Atomicity）
           要么都执行，要么都不执行

    一致性（Consistency）
           事务前后的数据都是正确的

    隔离性（Isolation）
          事物之间相互隔离，互不干扰（并发执行的事务彼此无法看到对方的中间状态）

    持久性（Durability）
           事务一旦提交不可再回滚



1.2.本地事务

在计算机系统中，更多的是通过关系型数据库来控制事务，这是利用数据库本身的事务特性来实现的，因此叫数据库事务，由于应用主要靠关系数据库来控制事务，而数据库通常和应用在同一个服务器，所以基于关系型数据库的事务又被称为本地事务。

1.2.1.数据库本身控制事物：

    begin transaction；
          //1.本地数据库操作：张三减少金额
          //2.本地数据库操作：李四增加金额
    rollback;
    或
    commit transation;



1.2.2.jdbc中使用事物：

 1.获取对数据库的连接

 2.设置事务不自动提交（默认情况是自动提交的）

    conn.setAutoCommit(false);   //其中conn是第一步获取的随数据库的连接对象。

 3.把想要一次性提交的几个sql语句用事务进行提交

    try{
        Statement stmt = null;
        stmt =conn.createStatement();
        stmt.executeUpdate(sql1);
        int a=6/0;
        stmt.executeUpdate(Sql2);
        .
        .
        .
        conn.commit();   //使用commit提交事务
    }

 4.捕获异常，进行数据的回滚（回滚一般写在catch块中）

    catch（Exception e） {
       ...
       conn.rollback();
    }

1.2.3.aop控制事务：

1.配置事务管理器

    <!--增强：配置事务管理器  -->
    <bean id="tm"class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
    		<property name="dataSource" ref="dataSource"></property>
    </bean>

2.配置事务的通知

    <!--配置事务的通知（增强）  -->
    <tx:advice id="txAdvice" transaction-manager="tm">
        <!--配置事务的传播行为  -->
        <tx:attributes>
            <tx:method name="add*" propagation="REQUIRED"/>
            <tx:method name="del*" propagation="REQUIRED"/>
            <tx:method name="update*" propagation="REQUIRED"/>
            <tx:method name="get*" read-only="true"/>
            <tx:method name="*" read-only="true"/>
        </tx:attributes>
    </tx:advice>

3.配置切面

    <!--配置切面：把增强应用到切点上  -->
    <aop:config>
       <!--切点 -->
       <aop:pointcut expression="execution(* com.usian.service.*.*(..))" id="pointcut"/>
       <!--切面 -->
       <aop:advisor advice-ref="txAdvice" pointcut-ref="pointcut"/>
    </aop:config>

1.3.分布式事务

 随着互联网的快速发展，软件系统由原来的单体应用转变为分布式应用，下图描述了单体应用向微服务的演变：



分布式系统会把一个应用系统拆分为可独立部署的多个服务，因此需要服务与服务之间远程协作才能完成事务操作，这种分布式系统环境下由不同的服务之间通过网络远程协作完成事务称之为分布式事务，例如用户注册送积分事务、创建订单减库存事务，银行转账事务等都是分布式事务。



我们知道本地事务依赖数据库本身提供的事务特性来实现，因此以下逻辑可以控制本地事务：

    begin transaction；
          //1.本地数据库操作：张三减少金额
          //2.本地数据库操作：李四增加金额
    commit transation;

但是在分布式环境下，会变成下边这样：

    begin transaction；
           //1.本地数据库操作：张三减少金额
           //2.远程调用：让李四增加金额
    commit transation;

可以设想，当远程调用让李四增加金额成功了，由于网络问题远程调用并没有返回，此时本地事务提交失败就回滚了张三减少金额的操作，此时张三和李四的数据就不一致了。

因此在分布式架构的基础上，传统数据库事务就无法使用了，张三和李四的账户不在一个数据库中甚至不在一个应用系统里，实现转账事务需要通过远程调用，由于网络问题就会导致分布式事务问题。

1.4.分布式事物产生的场景

1、典型的场景就是微服务架构 微服务之间通过远程调用完成事务操作。 比如：订单微服务和库存微服务，下单的同时订单微服务请求库存微服务减库存。简言之：跨JVM进程产生分布式事务。





2、单体系统访问多个数据库实例 当单体系统需要访问多个数据库（实例）时就会产生分布式事务。 比如：用户信息和订单信息分别在两个MySQL实例存储，用户管理系统删除用户信息，需要分别删除用户信息及用户的订单信息，由于数据分布在不同的数据实例，需要通过不同的数据库链接去操作数据，此时产生分布式事务。 简言之：跨数据库实例产生分布式事务。



3、多服务访问同一个数据库实例 比如：订单微服务和库存微服务即使访问同一个数据库也会产生分布式事务，两个微服务持有了不同的数据库链接进行数据库操作，此时产生分布式事务。简言之：跨JVM进程产生分布式事务。



2.RabbitMQ可靠消息最终一致性介绍

2.1.为什么要使用可靠消息最终一致性

       在实际系统的开发过程中，可能服务间的调用是异步的。也就是说，一个服务发送一个消息给 MQ，即消息中间件，比如RocketMQ、RabbitMQ、Kafka、ActiveMQ 等等。

       然后，另外一个服务从 MQ 消费到一条消息后进行处理。这就成了基于 MQ 的异步调用了。

       那么针对这种基于 MQ 的异步调用，如何保证各个服务间的分布式事务呢？也就是说，我希望的是基于MQ 实现异步调用的多个服务的业务逻辑，要么一起成功，要么一起失败。这个时候，就要用上可靠消息最终一致性方案，来实现分布式事务。

2.2.什么是可靠消息最终一致性

可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能够接收消息并处理事务成功，此方案强调的是只要消息发给事务参与方最终事务要达到一致。



此方案是利用消息中间件完成，如下图：



事务发起方（消息生产方）将消息发给消息中间件，事务参与方从消息中间件接收消息，事务发起方和消息中间件之间，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事务问题。

2.3.可靠消息最终一致性要解决的问题：

2.3.1.上游服务把信息成功发送

本地事务与消息发送的原子性问题：事务发起方在本地事务执行成功后消息必须发出去，否则就回滚事务。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。

2.3.2.下游服务成把消息成功消费

事务参与方接收消息的可靠性：事务参与方必须能够从消息队列接收到消息。

2.3.3.对消息做幂

消息重复消费的问题：由于网络2的存在，若某一个消费节点响应超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。

2.4.解决方案

2.4.1.问题一：上游服务把消息成功发送

针对问题一可采用消息表这个方案，该方案最初是eBay提出的，此方案的核心是：在系统A处理任务完成后，在本地记录待发送信息。一个定时任务不断检查，是否发送成功，如果发送成功，将记录状态修改。如下图：



2.4.2.问题二：下游服务成把消息成功消费

消息重试：消息持久化后，如果消息在投递过程中丢失，或消息的确认应答在返回途中丢失，那么消息中间件就会重新投递，直到下游消费者返回消费成功响应为止。

任务失败：当任务处理失败后，则返回给消息中间件失败，消息会重复发送



2.4.3.问题三：对消息做幂等

任务B处理消息前，先查询该消息是否被消费，如果没消费，处理任务B成功，记录消息。如果消息已经被消费，直接返回应答成功



3.RabbitMQ实现可靠消息最终一致性

3.1. 需求说明：

usian_order_service：

       1、保存订单信息

       2、保存本地消息记录

       3、向MQ Server发送转账消息

       4、在MQ Server响应返回后更新本地消息为已成功发送状态

usian_item_service：

       1、接收消息，扣减库存

       2、向MQ Server发送应答状态

       3、对扣减库存方法做幂等
2020-06-22
1.分布式日志

1.1.ELK介绍

1.1.1.什么是ELK?

ELK是Elasticsearch、Logstash、Kibana的简称（也称为 ELK Stack），是elastic公司提供的一套完整的
日志收集以及展示的解决方案，能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。
- Elasticsearch：是开源的分布式全文检索服务器。

- Logstash：是一个具有实时传输能力的数据收集引擎，用来进行数据收集（如：读取文本文件）、解析，并将数据发送给ES。

- Kibana：数据分析与可视化平台，对Elasticsearch存储的数据进行可视化分析，通过表格的形式展现出来。


1.1.2.为什么要用 ELK？

一般大型系统都采用分布式架构，不同的模块部署在不同的服务器上，大规模分布式项目的日志面临的问题如下：

1. 文本搜索太慢怎么办？
2. 分布式环境下的日志如何查询？
3. 如何多维度查询？
1.2.安装logstash
1.2.1.下载
下载地址：https://artifacts.elastic.co/downloads/logstash/logstash-6.2.3.tar.gz

1.2.2.安装
解压即安装：
    tar -zxvf logstash-6.2.3.tar.gz
    mv logstash-6.2.3 /usr/java/logstash
1.2.3.修改配置
在 logstash 的主目录下：
    vim config/log_to_es.conf
1.2.4.启动
启动命令：
    ./bin/logstash -f config/log_to_es.conf
    #或后台运行守护进程
    ./bin/logstash -f config/log_to_es.conf &
2020-06-24
1.MySql主从复制

1.1.安装mysql

1.1.1.下载

下载地址：https://dev.mysql.com/downloads/mysql/

1.1.2.卸载预装mysql

    #查看已安装：
    [root@centos upload]# rpm -qa|grep mysql
    #卸载：
    [root@centos upload]# rpm -e --nodeps mysql-libs-5.1.71-1.el6.x86_64
    #再次查看：
    [root@centos upload]# rpm -qa|grep mysql

1.1.3.上传安装包



1.1.4.解压安装包

    [root@centos upload]# tar -zxvf mysql-5.6.31-linux-glibc2.5-x86_64.tar.gz -C /usr/java
    [root@centos upload]# cd /usr/java
    [root@centos java]# mv mysql-5.6.31-linux-glibc2.5-x86_64 mysql

1.1.5.复制mysql的配置文件

    [root@centos java]# cd mysql
    [root@centos java]# cp support-files/my-default.cnf /etc/my.cnf
    [root@centos java]# cp support-files/mysql.server /etc/rc.d/init.d/mysql

1.1.6.修改my.cnf

    vim /etc/my.cnf

    basedir = /usr/java/mysql
    datadir = /usr/java/mysql/data
    log-error = /usr/java/mysql/data/error.log
    pid-file = /usr/java/mysql/data/mysql.pid
    user = root
    tmpdir = /tmp

1.1.7.初始化数据库

    [root@centos java]# cd /usr/java/mysql
    [root@centos mysql]# ./scripts/mysql_install_db --user=root --basedir=/usr/java/mysql --datadir=/usr/java/mysql/data --pid-file=/usr/java/mysql/data/mysql.pid --tmpdir=/tmp

1.1.8.启动和关闭mysql

    [root@centos mysql]# service mysql start
    Starting MySQL..                                          [确定]
    [root@centos mysql]# service mysql stop
    Shutting down MySQL..                                     [确定]
    [root@centos mysql]# service mysql restart
    Shutting down MySQL..
    Starting MySQL..                                          [确定]

1.1.8.配置mysql命令支持

如果提示没有mysql命令，需要添加软连接

    [root@centos mysql]# ln -s /usr/java/mysql/bin/mysql /usr/bin/mysql

1.1.9.修改MySQL密码

    [root@centos upload]# mysql -u root
    mysql> use mysql;
    mysql> update user set password= password("1111") where user='root';
    mysql> flush privileges;

1.1.10.开放远程登录权限

    mysql>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '1111' WITH GRANT OPTION;
    mysql>FLUSH PRIVILEGES;

1.1.11.设置开机启动

    [root@centos mysql]# chkconfig mysql on

1.2.MySQL主从复制

1.2.1.mysql主从简介

    1. MySQL 默认支持主(master)从(slave)功能.
    2. 主从复制效果：在主数据库中操作时,从同步进行变化.
    3. 主从复制本质：主数据的操作写入到日志中,从数据库从日志中读取,进行操作.



    主从备份要素：
        1. 开启日志功能
        2. 每个数据库需要有一个 server_id,主 server_id 值小于从server_id(标识从哪server写入的)
        3. 每个 mysql 都有一个 uuid,由于虚拟机直接进行克隆,需要修改uuid 的值(唯一识别码)
        4. 必须要在主数据库中有一个用户具有被从数据库操作的权限.



1.2.2.配置mysql主从步骤

1.2.2.1.克隆mysql1的虚拟机



1.2.2.2.配置主数据库

1、修改主数据库的my.cnf文件



2、重启mysql

    [root@centos upload]# service mysql restart

3、通过命令可以观察主数据库在主从关系中状态.



1.2.2.3.配置从数据库

1、修改server_id



2、data文件夹auto.cnf编写当前mysql的uuid



3、重启mysql

    [root@centos upload]# service mysql restart

4、修改slave

    mysql> stop slave;
    mysql> change master to master_host='192.168.159.142',master_user='root',master_password='1111',master_log_file='master_log.000001';
    mysql> start slave;

5、查看slave状态

    mysql>show slave status \G;

io线程和sql线程已开启：



只要没有错误,说明配置成功主从关系：



6、验证主从关系

      在主数据库中新建数据库,新建表,添加数据,观察从数据库的

2.MyCat

2.1.MyCat简介

MyCAT是一个数据库中间件。国产开源项目，前身是cobar项目。



2.2.Mycat对多数据库的支持



2.3.MyCAT架构

如图所示：MyCAT使用Mysql的通讯协议模拟成了一个Mysql服务器，所有能使用Mysql的客户端以及编程语言都能将MyCAT当成是Mysql Server来使用，不必开发新的客户端协议。



2.4.MyCat分库分表

垂直分割（分库）：指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面，如下图：



水平分割（分表）：一个表格的数据按照行分割到多个节点上，如图：



典型的分片规则：

	根据主键编号进行hash、求余，如图



2.5.MyCat安装

2.5.1.下载mycat

官方网站：http://www.mycat.org.cn/

github地址：https://github.com/MyCATApache

2.5.2.安装Mycat

1、把MyCat的压缩包上传到linux服务器



2、解压缩，得到mycat目录

    [root@centos upload]# tar -zxvf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz -C /usr/java

3、启动和关闭MyCat

    进入mycat/bin，启动MyCat
    启动命令：./mycat start
    停止命令：./mycat stop
    重启命令：./mycat restart
    查看状态：./mycat status

注意：可以使用mysql的客户端直接连接mycat服务。默认服务端口为8066

3.Mycat分库分表和读写分离

3.1.需求

把商品表分片存储到两个数据节点上。

3.2.安装环境

mysql节点1环境

    操作系统版本 : centos6.5
    数据库版本 :mysql-5.6
    数据库名 : db1
    ip:192.168.25.134

mysql节点2环境

    操作系统版本 :centos6.5
    数据库版本 :mysql-5.6
    数据库名 : db2
    ip:192.168.25.135

mysql节点3环境

    操作系统版本 :centos6.5
    数据库版本 :mysql-5.6
    数据库名 : db3
    ip:192.168.25.136

mycat节点环境

    操作系统版本 :centos6.5
    mycat版本：1.6release
    ip:192.168.25.137

3.4.MyCat重要概念

    1、逻辑库（schema）：一个包含了所有数据库的逻辑上的数据库

    2、逻辑表（table）：一个包含了所有表的逻辑上的表

    3、数据主机（dataHost）：数据库软件安装到哪个服务器上

    4、数据节点（dataNode）：数据库软件中的 database

    5、分片规则（rule）：拆分规则

3.5. 配置schema.xml

3.5.1.Schema.xml介绍

Schema.xml作为MyCat中重要的配置文件之一，管理着MyCat的逻辑库、表、分片规则、DataNode以及DataSource。

3.5.2.Schema.xml配置

    <?xml version="1.0"?>
    <!DOCTYPE mycat:schema SYSTEM "schema.dtd">
    <mycat:schema xmlns:mycat="http://io.mycat/">
    	<schema name="usian" checkSQLschema="false" sqlMaxLimit="100">
             <table name="tb_content" dataNode="dn1,dn2,dn3" rule="crc32slot" />
    		<table name="tb_content_category" dataNode="dn1,dn2,dn3" rule="crc32slot1"/>
    		<table name="tb_item" dataNode="dn1,dn2,dn3" rule="crc32slot2" />
    		<table name="tb_item_cat" dataNode="dn1,dn2,dn3" rule="crc32slot3" />
    		<table name="tb_item_desc" dataNode="dn1,dn2,dn3" rule="crc32slot4"  />
    		<table name="tb_item_param" dataNode="dn1,dn2,dn3" rule="crc32slot5"  />
    		<table name="tb_item_param_item" dataNode="dn1,dn2,dn3" rule="crc32slot6" />
    		<table name="tb_order" dataNode="dn1,dn2,dn3" rule="crc32slot7" />
    		<table name="tb_order_item" dataNode="dn1,dn2,dn3" rule="crc32slot8" />
    		<table name="tb_order_shipping" dataNode="dn1,dn2,dn3" rule="crc32slot9" />
    		<table name="tb_user" dataNode="dn1,dn2,dn3" rule="crc32slot10" />
    	</schema>

    	<dataNode name="dn1" dataHost="localhost1" database="db1" />
    	<dataNode name="dn2" dataHost="localhost1" database="db2" />
    	<dataNode name="dn3" dataHost="localhost1" database="db3" />

    	<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
    		writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
    		<heartbeat>select user()</heartbeat>
    		<writeHost host="hostM1" url="192.168.233.137:3306" user="root" password="1111">
    			<readHost host="hostS2" url="192.168.233.138:3306" user="root" password="1111" />
    		</writeHost>
    	</dataHost>
    </mycat:schema>

3.6. 配置server.xml

3.6.1.server.xml介绍

server.xml几乎保存了所有mycat需要的系统配置信息。最常用的是在此配置用户名、密码及权限。

3.6.2.server.xml配置

    <user name="root">
        <property name="password">1111</property>
        <property name="schemas">usian</property>
    </user>

    <user name="user">
        <property name="password">1111</property>
        <property name="schemas">usian</property>
        <property name="readOnly">true</property>
    </user>

3.7.配置rule.xml

3.7.1.分片规则

3.7.1.1.auto-sharding-long 规则

    以 500 万为单位,实现分片规则：
    1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db3 中.

3.7.1.2.crc32slot  规则

    在 CRUD 操作时,根据具体数据的 crc32 算法计算,数据应该保存在哪一个dataNode 中

3.7.2.rule.xml配置

    1）<columns>id</columns>中推荐配置主键列

    2）所有的 tableRule 只能使用一次。如果需要为多个表配置相同的分片规则，那么需要在此重新定义该规则。

    3) 要分片的数据库节点数量，必须指定，否则没法分片

    <tableRule name="crc32slot1">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot2">
        <rule>
       	 	<columns>id</columns>
       		<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot3">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot4">
        <rule>
        	<columns>item_id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot5">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot6">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot7">
        <rule>
        	<columns>order_id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot8">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot9">
        <rule>
        	<columns>order_id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot10">
        <rule>
        	<columns>id</columns>
        	<algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>

    <function name="crc32slot" class="io.mycat.route.function.PartitionByCRC32PreSlot">
        <property name="count">3</property><!-- 要分片的数据库数量，必须指定，否则没法分片 -->
    </function>
3.8.测试
3.8.1.创建库
在主数据库中分别创建db1、db2、db3
3.8.2.创建表并插入数据
配置完毕后，重新启动mycat。
使用mysql客户端连接mycat，创建表并插入数据。
3.8.3.分库测试
3.8.4.项目测试
1、修改数据库url
    spring:
      application:
        name: usian-item-service
      datasource:
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://192.168.233.139:8066/usian?characterEncoding=UTF-8
        username: root
        password: 1111
        type: com.alibaba.druid.pool.DruidDataSource
2、测试

2020-06-28
.Swagger
2.1.Swagger是什么？

Swagger[ˈswæɡə(r)，丝袜哥] ：是一个实现了OpenAPI规范的工具集，用于生成API文档并提供可视化 RESTful 风格的 Web 服务。

OpenAPI规范（OpenAPI Specification 简称OAS）是Linux基金会的一个项目，试图通过定义一种用来描述API格式或API定义的语言，来规范RESTful服务开发过程。目前V3.0版本的OpenAPI规范已经发布并开源在github上 。

2.2.为什么要使用Swagger？

随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、前后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。  前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要。

没有API文档工具之前，大家都是手写API文档的，在什么地方书写的都有，而且API文档没有统一规范和格式，每个公司都不一样。

1.网关服务

1.1.网关服务分析

1.1.1.需求

1.1.1.1.路由

所有请求都通过网关访问服务的consumer

1.1.1.2.容错

客户端通过zuul无法调用consumer时，使用zuul对consumer进行降级

1.1.1.3.限流

使用令牌桶算法实现zuul对consumer的限流
1.2.工程搭建

1.2.1.创建common_zuul

1.2.1.1.创建工程



1.2.1.2.pom.xml

    <?xml version="1.0" encoding="UTF-8"?>
    <project xmlns="http://maven.apache.org/POM/4.0.0"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
        <parent>
            <artifactId>usian_parent</artifactId>
            <groupId>com.usian</groupId>
            <version>1.0-SNAPSHOT</version>
        </parent>
        <modelVersion>4.0.0</modelVersion>

        <artifactId>common_zuul</artifactId>

        <dependencies>
            <!--Spring Boot Web Starter-->
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-starter-web</artifactId>
            </dependency>
            <!--Spring Cloud Eureka Client Starter-->
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
            </dependency>
            <!--Spring Cloud Zuul Starter-->
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-starter-netflix-zuul</artifactId>
            </dependency>
        </dependencies>
    </project>

1.2.1.3.application.yml

    spring:
      application:
        name: common-zuul
    server:
      port: 7070
    eureka:
      client:
        service-url:
          defaultZone: http://127.0.0.1:8761/eureka/
    zuul:
      ignored-services: * #忽略的服务,多个可以用*
    ######################################################################
    #第一层 hystrix 超时时间设置
    hystrix:
      command:
        default:
          execution:
            isolation:
              thread:
                timeoutInMilliseconds: 8000 #默认情况下是线程池隔离，超时时间 1000ms
    #第二层 ribbon 超时时间设置：设置比第一层小
    ribbon:
      ConnectTimeout: 5000 #请求连接的超时时间: 默认 5s
      ReadTimeout: 5000 #请求处理的超时时间: 默认 5s
    ######################################################################

1.2.1.4.logback.xml

    <?xml version="1.0" encoding="UTF-8" ?>
     <configuration>
    <!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径-->
        <property name="LOG_HOME" value="${catalina.base}/logs/" />
        <!-- 控制台输出 -->
        <appender name="Stdout" class="ch.qos.logback.core.ConsoleAppender">
           <!-- 日志输出编码 -->
            <layout class="ch.qos.logback.classic.PatternLayout">
                 <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符-->
                <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n
                </pattern>
            </layout>
        </appender>
        <!-- 按照每天生成日志文件 -->
        <appender name="RollingFile"  class="ch.qos.logback.core.rolling.RollingFileAppender">
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <!--日志文件输出的文件名-->
                <FileNamePattern>${LOG_HOME}/server.%d{yyyy-MM-dd}.log</FileNamePattern>
                <MaxHistory>30</MaxHistory>
            </rollingPolicy>
            <layout class="ch.qos.logback.classic.PatternLayout">
                <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符-->
                <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n
                </pattern>
           </layout>
            <!--日志文件最大的大小-->
           <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
             <MaxFileSize>10MB</MaxFileSize>
           </triggeringPolicy>
        </appender>

    	 <!--myibatis log configure-->

        <!-- 日志输出级别 -->
        <root level="DEBUG">
            <appender-ref ref="Stdout" />
            <appender-ref ref="RollingFile" />
        </root>



    <!--日志异步到数据库 -->
    <!--     <appender name="DB" class="ch.qos.logback.classic.db.DBAppender">
            日志异步到数据库
            <connectionSource class="ch.qos.logback.core.db.DriverManagerConnectionSource">
               连接池
               <dataSource class="com.mchange.v2.c3p0.ComboPooledDataSource">
                  <driverClass>com.mysql.jdbc.Driver</driverClass>
                  <url>jdbc:mysql://127.0.0.1:3306/databaseName</url>
                  <user>root</user>
                  <password>root</password>
                </dataSource>
            </connectionSource>
      </appender> -->

    </configuration>

1.2.1.5.创建启动类

    package com.usian;

    import org.springframework.boot.SpringApplication;
    import org.springframework.boot.autoconfigure.SpringBootApplication;
    import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
    import org.springframework.cloud.netflix.zuul.EnableZuulProxy;

    /**
     * CommonZuulServer
     */
    @SpringBootApplication
    @EnableDiscoveryClient
    @EnableZuulProxy
    public class ZuulApp {
        public static void main(String[] args) {
            SpringApplication.run(ZuulApp.class, args);
        }
    }

1.3.网关路由

1.3.1.配置后台服务代理

1.3.1.1.usian-manage-web

1.3.1.1.1.vue.config.js

 修改 vue.config.js

    module.exports = {
        devServer: {
            proxy: {
                '/product_api': {
                    //target: 'http://127.0.0.1:8091',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/product_api': ''
                    },
                    changeOrigin: true
                },
                '/content_api': {
                    //target: 'http://127.0.0.1:8093',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/content_api': ''
                    },
                    changeOrigin: true
                },
                '/search_api': {
                    //target: 'http://127.0.0.1:8096',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/search_api': ''
                    },
                    changeOrigin: true
                }
            },
            disableHostCheck: true
        }
    }


1.3.1.1.2.base.js

修改src/api/base.js

    const base = {
        baseUrl:"/api",
        basePrductUrl:"/product_api/backend_item",
        baseContentUrl:"/content_api/backend_content",
        baseSearchUrl:"/search_api/frontend_search",
        ... ... ...
    }

1.3.1.2.common_zuul

1.3.1.2.1.application.yml

    #第一层 hystrix 超时时间设置
    hystrix:
      command:
        default:
          execution:
            isolation:
              thread:
                timeoutInMilliseconds: 8000 #默认情况下是线程池隔离，超时时间 1000ms
    #第二层 ribbon 超时时间设置：设置比第一层小
    ribbon:
      ConnectTimeout: 3000 #请求连接的超时时间: 默认 5s
      ReadTimeout: 3000 #请求处理的超时时间: 默认 5s

    zuul:
      routes:
        usian-item-web:
          path: /backend_item/**
        usian-content-web:
          path: /backend_content/**
        usian-search-web:
          path: /frontend_search/**

1.3.2.配置前台服务代理

1.3.2.1.usian-portal-web

1.3.2.1.1.vue.config.js

 修改 vue.config.js

    module.exports = {
        // publicPath: process.env.NODE_ENV === 'production'
        //     ? ''
        //     : '/',
        devServer: {
            port:8081,
            proxy: {
                '/api': {
                    //target: 'http://127.0.0.1:8094',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/api': ''
                    },
                    changeOrigin: true
                },
                '/search_api': {
                    //target: 'http://127.0.0.1:8096',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/search_api': ''
                    },
                    changeOrigin: true
                },
                '/detail_api': {
                    //target: 'http://127.0.0.1:8097',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/detail_api': ''
                    },
                    changeOrigin: true
                },
                '/shopcar_api': {
                    //target: 'http://127.0.0.1:8101',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/shopcar_api': ''
                    },
                    changeOrigin: true
                },
                "/payment_api": {
                    //target: 'http://127.0.0.1:8103',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/payment_api': ''
                    },
                    changeOrigin: true
                },
                "/register_api": {
                    //target: 'http://127.0.0.1:8099',
                    target: 'http://127.0.0.1:7070',
                    pathRewrite: {
                        '^/register_api': ''
                    },
                    changeOrigin: true
                }
            }
        }
    }

1.3.2.1.2.base.js

修改src/api/base.js

    const base = {
        baseUrl: '/api/frontend_portal',
        shopcarBaseUrl: "/shopcar_api/frontend_cart",
        searchBaseUrl: "/search_api/frontend_search",
        detailBaseUrl: "/detail_api/frontend_detail",
        registerBaseUrl: "/register_api/frontend_sso",
        payMentBaseUrl:"/payment_api/frontend_order",
        ... ... ...
    }

1.3.2.2.common_zuul

1.3.2.2.1.application.yml

    zuul:
      routes:
        sensitive-headers: true #全局配置，解决在网关服务中不传递请求头的问题
        usian-portal-web:
          path: /frontend_portal/**
        usian-detail-web:
          path: /frontend_detail/**
        usian-sso-web:
          path: /frontend_sso/**
        usian-cart-web:
          path: /frontend_cart/**
        usian-order-web:
          path: /frontend_order/**

1.3.3.测试

测试商城前台和后台是否能正常访问

1.4.网关容错

1.4.1.common_zuul

1.4.1.1.fallback

    package com.usian.fallback;

    import org.springframework.cloud.netflix.zuul.filters.route.FallbackProvider;
    import org.springframework.http.HttpHeaders;
    import org.springframework.http.HttpStatus;
    import org.springframework.http.MediaType;
    import org.springframework.http.client.ClientHttpResponse;
    import org.springframework.stereotype.Component;

    import java.io.ByteArrayInputStream;
    import java.io.IOException;
    import java.io.InputStream;
    import java.nio.charset.Charset;

    @Component
    public class ConsumerFallback implements FallbackProvider {
        @Override
        public String getRoute() {
            //降级的服务名，多个服务return "*"
            return "*";
        }

        /**
         * 当服务无法执行时，该方法返回托底信息
         */
        @Override
        public ClientHttpResponse fallbackResponse(String route, Throwable cause) {
            return new ClientHttpResponse() {

                /**
                 * 设置响应的头信息
                 */
                @Override
                public HttpHeaders getHeaders() {
                    HttpHeaders header = new HttpHeaders();
                    httpHeaders.setContentType(MediaType.APPLICATION_JSON_UTF8);
                    return header;
                }

                /**
                 * 设置响应体
                 */
                @Override
                public InputStream getBody() throws IOException {
                    String content = "该服务暂时不可用，请稍后重试";
                    return new ByteArrayInputStream(content.getBytes());
                }

                /**
                 * ClientHttpResponse的fallback的状态码 返回String
                 */
                @Override
                public String getStatusText() throws IOException {
                    return this.getStatusCode().getReasonPhrase();
                }

                /**
                 * 网关向api服务请求是失败了，但是消费者客户端向网关发起的请求是OK的，
                 * 不应该把api的404,500等问题抛给客户端
                 * 网关和api服务集群对于客户端来说是黑盒子
                 */
                @Override
                public HttpStatus getStatusCode() throws IOException {
                    return HttpStatus.OK;
                }

                /**
                 * ClientHttpResponse的fallback的状态码 返回int
                 */
                @Override
                public int getRawStatusCode() throws IOException {
                    return this.getStatusCode().value();
                }
                @Override
                public void close() {

                }
            };
        }
    }

1.4.2.测试
后台网关容错：
前台网关容错：
1.5.网关限流
1.5.1.common_zuul
1.5.1.1.filter
1.5.2.测试










