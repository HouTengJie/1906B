2020-06-01：
一、ElasticSearch介绍
   1、什么是elasticsearch?
ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个基于RESTful web接口的分布式全文搜索引擎。ElasticSearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。ElasticSearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。根据DB-Engines的排名显示，ElasticSearch是最受欢迎的企业搜索引擎，其次是Apache Solr（也是基Lucene）。
总结：
​ 1、elasticsearch是一个基于Lucene的分布式全文检索服务器。
​ 2、elasticsearch隐藏了Lucene的复杂性，对外提供Restful 接口来操作索引、搜索。
es和solr选择哪个？
1.如果你公司现在用的solr可以满足需求就不要换了。
2.如果你公司准备进行全文检索项目的开发，建议优先考虑elasticsearch，因为像Github这样大规模的搜索都在用它。


2、elasticsearch原理
索引结构
​ 下图是ElasticSearch的索引结构，右边黑蓝色色部分是原始文档，左边黄色部分是逻辑结构，逻辑结构也是为了更好的去描述ElasticSearch的工作原理及去使用物理结构中的索引文件。

倒排索引
倒排索引（Inverted index）:也常被称为反向索引，倒排索引是从关键字到文档的映射（已知关键字求文档）。
逻辑结构部分是一个倒排索引表，由三部分组成：
1、将搜索的文档最终以<font color=red>Document</font>方式存储起来。
2、将要搜索的文档内容分词，所有不重复的词组成<font color=red>分词</font>列表。
3、每个分词和docment都有<font color=red>关联</font>。



现在，如果我们想搜索 包含quick brown词条的文档：

两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。

二、ES安装
环境需求
1、jdk必须是jdk1.8.0_131以上版本。
2、ElasticSearch 需要至少4096 的线程池才能正常启动，ES 至少需要 65536 的文件创建权限，所以需要为虚拟机分配至少1.5G以上的内存
3、从5.0开始，ElasticSearch 安全级别提高了，不允许采用root帐号启动
4、Elasticsearch的插件要求至少3.5以上版本
	a、安装
		1、设置虚拟机内存>1.5G
		2、创建用户
		3、安装
			解压即安装
			配置elasticsearch.yml
		4、解决内核问题
		5、解决文件创建权限问题
		6、决绝线程开启限制问题
		7、解决虚拟机内存问题

	b、启动和关闭
		启动：
			./bin/elasticsearch
			./elasticsearch -d

		关闭：			kill -9 pid



2020-06-02：
三、ES快速入门
 1、index管理
1.创建index
索引：包含若干相似结构的 Document 数据，相当于数据库的database。
语法：

PUT /java1906
{
  "settings": {
    "number_of_shards": 2,
    "number_of_replicas": 0
  }
}
number_of_shards - 是表示一个索引库将拆分成多片分别存储不同的结点，提高了ES的处理能力和高可用性
number_of_replicas- 是为每个 primary shard分配的replica shard数，如果只有一台机器，设置为0

2.修改index
注意：索引一旦创建，primary shard 数量不可变化，可以改变replica shard 数量。

PUT /java1906/_settings
{
  "number_of_replicas" : 1
}
ES 中对 shard 的分布是有要求的，有其内置的特殊算法：
​ Replica shard 会保证不和他的那个 primary shard 分配在同一个节点上；如过只有一个节点，则此案例执行后索引的状态一定是yellow。
3.删除index
DELETE /java1906 [, other_index]
2.mapping管理
映射，创建映射就是向索引库中创建field（类型、是否索引、是否存储等特性）的过程，下边是document和field与关系数据库的概念的类比：
​ 索引库（index）--------------------------------Database数据库
​ 类型（type）-----------------------------Table数据表
​ 文档（Document）----------------Row 行
​ 字段（Field）-------------------Columns 列
注意：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES6.x 版本之后，type概念被弱化ES官方将在ES7.0版本中彻底删除type。

1.创建mapping
语法：POST index_name/type_name/_mapping
如：

POST /java1906/course/_mapping
{
  "properties": {
     "name": {
        "type": "text"
     },
     "description": {
        "type": "text"
     },
     "studymodel": {
        "type": "keyword"
     }
  }
}
2.查询mapping
查询所有索引的映射：

GET /java1906/course/_mapping

3、doucument管理
a、创建doucment
		POST /java1907/couse/1
		{
			"name":"php从入门到放弃"
		}
		POST /java1907/couse
		{
			"name":"php从入门到放弃"
		}
		PUT /java1907/couse/1
		{
			"name":"php从入门到放弃"
		}
b、查询doucument
		如：根据课程id查询文档
GET /java1906/course/1
如：查询所有记录
GET /java1906/course/_search
如：查询名称中包括php 关键字的的记录
GET /java1906/course/_search?q=name:门

	c、删除document
		DELETE /java1906/couse/1

四、IK分词器
  1、安装
	解压到plugs目录下，并重命名为ik

    2、自定义词库
	IkAnalyzer.cfg.xml：配置扩展词典和停用词典
	main.dic：扩展词典
	stopwords.dic：停用词典

3、两种分词模式
ik分词器有两种分词模式：ik_max_word和ik_smart模式。
1、ik_max_word
​ 会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人		民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、		会堂等词语。
2、ik_smart
​ 会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和		国、人民大会堂。
五、field详细介绍
1.field的属性介绍
1.type：
通过type属性指定field的类型。

"name":{
       "type":"text"
}
2.analyzer：
通过analyzer属性指定分词模式。
 "name": {
               "type": "text",
               "analyzer":"ik_max_word"
   }
上边指定了analyzer是指在索引和搜索都使用ik_max_word，如果单独想定义搜索时使用的分词器则可以通过search_analyzer属性。对于ik分词器建议是索引时使用ik_max_word将搜索内容进行细粒度分词，搜索时使用ik_smart提高搜索精确性。

"name": {
                  "type": "text",
                  "analyzer":"ik_max_word",
                  "search_analyzer":"ik_smart"
 }
3.index：
通过index属性指定是否索引。默认为index=true，即要进行索引，只有进行索引才可以从索引库搜索到。但是也有一些内容不需要索引，比如：商品图片地址只被用来展示图片，不进行搜索图片，此时可以将index设置为false。 删除索引，重新创建映射，将pic的index设置为false，尝试根据pic去搜索，结果搜索不到数据
"pic": {
       "type":"text",          
       "index":false
}
2.field索引不存储
​ 如果某个字段内容非常多，业务里面只需要能对该字段进行搜索，比如：商品描述。查看文档内容会再次到mysql或者hbase中取数据，把大字段的内容存在Elasticsearch中只会增大索引，这一点文档数量越大结果越明显，如果一条文档节省几KB，放大到亿万级的量结果也是非常可观的。
如果只想存储某几个字段的原始值到Elasticsearch，可以通过incudes参数来设置，在mapping中的设置如下:
POST /java1906/course/_mapping
{
  "_source": {
    "includes":["description"]
  }
}
同样，可以通过excludes参数排除某些字段：
POST /java1906/course/_mapping
{
  "_source": {
    "excludes":["description"]
  }
}
4.常用field类型
1.text文本字段
例如：1、创建新映射：

POST /java1906/course/_mapping
{
  "properties": {  
       "name": {
           "type": "text",
           "analyzer":"ik_max_word",
           "search_analyzer":"ik_smart"
       },        
      "description": {
          "type": "text",
          "analyzer":"ik_max_word",
          "search_analyzer":"ik_smart"
      },
      "pic":{
          "type":"text",
          "index":false
      },
      "studymodel":{
          "type":"text"
      }
  }  
}
2、插入文档：

POST /java1906/course/1
{
  "name":"python从入门到放弃",
  "description":"人生苦短，我用Python",
  "pic":"250.jpg",
  "studymodel":"201002"
}
3.查询测试：

GET /java1906/course/_search?q=name:放弃
GET /java1906/course/_search?q= description:人生
GET /java1906/course /_search?q=pic:250.jpg
结果：name和description都支持全文检索，pic不可作为查询条件
4.keyword关键字字段
上边介绍的text文本字段在映射时要设置分词器，keyword字段为关键字字段，通常搜索keyword是按照整体搜索，所以创建keyword字段的索引时是不进行分词的，比如：邮政编码、手机号码、身份证等。keyword字段通常用于过虑、排序、聚合等。
1、更改映射：

POST /java1906/course/_mapping
{
    "properties": {
       "studymodel":{
          "type":"keyword"
       },
       "description": {
          "type": "text",
          "analyzer":"ik_max_word",
          "search_analyzer":"ik_smart"
       },
       "pic":{
         "type":"text",
         "index":false
       },
       "name":{
          "type":"keyword"
       }
    }
}
2、插入文档：
PUT /java1906/course/2
{
 "name": "java编程基础",
 "description": "java语言是世界第一编程语言",
 "pic":"250.jpg",
 "studymodel": "201001"
}
3、根据name查询文档：
GET /java1906/course/_search?q=name:java编程基础
name是keyword类型，所以查询方式是精确查询。
5.date日期类型
日期类型不用设置分词器，通常日期类型的字段用于排序。1)format通过format设置日期格式，多个格式使用双竖线||分隔, 每个格式都会被依次尝试, 直到找到匹配的
1、设置允许date字段存储年月日时分秒、年月日及毫秒三种格式。
POST /java1906/course/_mapping
{
    "properties": {
       "timestamp": {
         "type":   "date",
         "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd"
       }
     }
}
2、插入文档：
PUT /java1906/course/3
{
"name": "spring开发基础",
"description": "spring 在java领域非常流行，java程序员都在用。",
"studymodel": "201001",
 "pic":"250.jpg",
 "timestamp":"2018-07-04 18:28:58"
}
6.Numeric类型
下图是ES支持的数值类型：尽可能选择范围小的数据类型,字段的长度越短, 索引和搜索的效率越高;

1、更新已有映射：
POST /java1906/course/_mapping
{
    "properties": {
    "price": {
        "type": "double"
     }
  }
}
2、插入文档
PUT /java1906/course/3
{
 "name": "spring开发基础",
 "description": "spring 在java领域非常流行，java程序员都在用。",
 "studymodel": "201001",
 "pic":"250.jpg",
 "timestamp":"2018-07-04 18:28:58",
 "price":38.6
}


2020-06-03：
六、Spring Boot整合ElasticSearch
1.搭建工程
1.pom.xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.1.6.RELEASE</version>
    </parent>

    <groupId>com.usian</groupId>
    <artifactId>springboot_elasticsearch</artifactId>
    <version>1.0-SNAPSHOT</version>
    <properties>
        <java.version>1.8</java.version>
    </properties>
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>elasticsearch-rest-high-level-client</artifactId>
        </dependency>
        <dependency>
            <groupId>org.elasticsearch</groupId>
            <artifactId>elasticsearch</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
        </dependency>
    </dependencies>
</project>
2.application.yml
spring:
  data:
    elasticsearch:
      cluster-nodes: 192.168.233.134:9200
3.Config
package com.usian.config;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class ElasticsearchConfig extends ElasticsearchProperties{

	@Bean
	public RestHighLevelClient getRestHighLevelClient() {
        String[] hosts = getClusterNodes().split(",");
        HttpHost[] httpHosts = new HttpHost[hosts.length];
        for (int i = 0; i < httpHosts.length; i++) {
            String h = hosts[i];
            httpHosts[i] = new HttpHost(h.split(":")[0],Integer.parseInt(h.split(":")[1]));
        }
		return new RestHighLevelClient(RestClient.builder(httpHosts));
	}
4.app
package com.usian;
​
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
​
@SpringBootApplication
public class ElasticsearchApp {
​
    public static void main(String[] args) {
        SpringApplication.run(ElasticsearchApp.class, args);
    }
}
2.索引管理
1.创建索引库
	CreateIndexRequest createIndexRequest = new CreateIndexRequest("java1906");
	createIndexRequest.settings("");
	createIndexRequest.mapping("");
	restHighLevelClient.indices().create(createIndexRequest,RequestOptions.DEFAULT)


2.删除索引库
	DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest("java1906");
	restHighLevelClient.indices().delete(deleteIndexRequest,RequestOptions.DEFAULT);

3.添加文档
	IndexRequest indexRequest = new IndexRequest("java1906", "course", "1");
	indexRequest.source();
	restHighLevelClient.index(indexRequest,RequestOptions.DEFAULT);

4.批量添加文档
	BulkRequest bulkRequest = new BulkRequest();
	bulkRequest.add(new IndexRequest("java1906", "course", "1").source(""));
	bulkRequest.add(new IndexRequest("java1906", "course", "1").source(""));
	restHighLevelClient.bulk(bulkRequest,RequestOptions.DEFAULT);

5.修改文档
	UpdateRequest updateRequest = new UpdateRequest("java1906", "course", "1");
	indexRequest.doc("");
	restHighLevelClient.update(indexRequest,RequestOptions.DEFAULT);

6.删除文档
	DeleteRequest deleteRequest = new DeleteRequest("java1906", "course", "1");
	restHighLevelClient.delete(deleteRequest,RequestOptions.DEFAULT);

7.简单搜索
	GetRequest getRequest = new GetRequest("java1906", "course", "1");
	restHighLevelClient.get(getRequest,RequestOptions.DEFAULT);

8.dsl搜索
	1、match_all
		SearchRequest searchRequest = new SearchRequest("java1906");
		searchRequest.types("course");

		SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
		searchSourceBuilder.query(QueryBuilders.matchAllQuery());

		searchRequest.search(searchSourceBuilder)
		restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);

	2、分页查询
		SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
		searchSourceBuilder.query(QueryBuilders.matchAllQuery());
		searchSourceBuilder.form(1);
		searchSourceBuilder.size(2);
		searchSourceBuilder.sort("price",SortOrder.DESC);
2020-06-05
   商品搜索：
           搜索展示的商品信息：
               对应的业务域：
              	   1、商品Id  2、商品标题  3、商品卖点  4、商品价格  5、商品图片  6、分类名称  7、商品描述
               需要从tb_item, tb_item_cat, tb_item_desc表中查询商品数据：
               根据前端传过来的搜索条件，到后台进行查询，名字，描述，卖点，类别，这些域，同时进行数据分页和搜索条件的
           高亮处理，最后返回一个结果集，完成查询

   索引库同步：
	   索引库同步，这个索引库同步是使用MQ实现的,MQ的主要作用有，应用解耦，流量削锋，异步处理。在商品添加的
              时候，将添加的数据ID发送到MQ中，然后在ElasticSearch模块的服务消费者，配置MQ的队列监听，收到消息后，
              通过ID去数据库中查询信息，并添加到ElasticSearch中，实现索引库同步


2020-06-08
1.商品详情的方案

1.1.网页静态化方案

1、创建商品详情的thymeleaf模板

2、创建一个RabbitMQ的消费者，收到消息后创建静态页面

3、搭建nginx服务器，返回静态页面

1.2.redis缓存商品信息方案

使用redis做缓存，业务逻辑：

1、根据商品id到redis中查询,查得到，直接返回

2、查不到，查询mysql, 数据放到redis中设置缓存的有效期一天的时间，可以根据实际情况调整。

需要使用String类型来保存商品数据，可以加前缀对redis中的key进行归类：

ITEM_INFO:123456:BASE

ITEM_INFO:123456:DESC

ITEM_INFO:123456:PARAM

2.查询商品详情

2.1.创建usian_detail_web
2.2.查询商品信息
4.缓存穿透
3.1.描述
缓存穿透是指缓存和数据库中都没有数据，而用户不断发起请求则这些请求会穿过缓存直接访问数据库，
如发起为id为“-1”的数据或id为特别大不存在的数据。假如有恶意攻击，就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。
3.2.解决方案
缓存空对象：
当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间（避免控制占用更多的存储空间），
之后再访问这个数据将会从缓存中获取，保护了后端数据源；

4缓存击穿
4.1.描述

缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个key不停进行访问，
当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

2020-06-09:
1.单点登录介绍
1.1.什么是单点登录
SSO英文全称Single Sign On，单点登录。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统，
例如：【百度：百度文库、百度外卖】、【淘宝：淘宝、天猫】、【优思安：门户、搜索、商品详情】。
它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一。

1.2.为什么要有单点登录系统
集群环境下会出现要求用户多次登录的情况。
解决方案：
1、配置tomcat集群(500)。配置tomcat Session复制。节点数不要超过5个。

2、可以使用Session服务器（sso系统），保存Session信息。需要模拟Session。

session和redis的共同特点：

1、kv形式存储

2、过期时间

单点登录系统是使用redis模拟Session，实现Session的统一管理。

1.3.需求分析

1.3.1.登录

把用户信息装到redis(token，user)，再把token装到cookie(token_key,token)

1.3.2.查询

先从cookie中取出token，再通过token从redis中查询用户信息

2.工程搭建

2.1.创建usian_sso_service

2.1.1.创建工程
2.1.2.pom.xml
2.1.3.application.yml
2.1.4.logback.xml
2.1.5.创建启动类

2.2.创建usian_sso_feign
2.2.1.创建工程
2.2.2.pom.xml

2.3.创建usian_sso_web
2.3.1.创建工程
2.3.2.pom.xml
2.3.3.application.yml
2.3.4.logback.xml
2.3.5.创建启动类

2.注册信息校验
2.1.usian_sso_service
2.1.1.service
2.1.2.controller

2.2.usian_sso_feign
2.2.1.feign

2.3.usian_sso_web
2.3.1.controller

3.用户注册
3.1.usian_sso_service
3.1.1.service
3.1.2.controller

3.2.usian_sso_feign
3.2.1.feign

3.3.usian_sso_web
3.3.1.controller

4.用户登录
4.1.usian_sso_service
4.1.1.service
4.1.2.controller

4.2.usian_sso_feign
4.2.1.feign

4.3.usian_sso_web
4.3.1.controller

4.4.测试
1、观察cookie
2、测试是否显示登录用户名

5.通过token查询用户信息
5.1.业务逻辑
1、从url中取参数token
2、根据token查询redis
3、如果查询不到数据，前台删除cookie中的用户信息
4、如果查询到数据，说明用户已经登录需要重置key的过期时间

5.2.usian_sso_service
5.2.1.service
5.2.2.controller

5.3.usian_sso_feign
5.3.1.feign

5.4.usian_sso_web
5.4.1.controller

5.5.测试
测试是否显示登录用户名

6.退出登录
6.1.usian_sso_service
6.1.1.service
6.1.2.controller

6.2.usian_sso_feign
6.2.1.feign

6.3.usian_sso_web
6.3.1.controller
6.4.测试
2020-06-10
1.购物车设计
1. 用户未登录状态下：在不登陆的情况下把购物车信息写入cookie
   	优点：
   		1、不占用服务端存储空间
   		2、代码实现简单。
   		3、用户体验好
   	缺点：
   		1、cookie中保存的容量有限。最大4k
   		2、把购物车信息保存在cookie中，更换设备购物车信息不能同步。
2. 用户已登录状态下：把购物车信息保存到服务端的 Redis 中
   	优点：
   		1、更换设备购物车信息可以同步
   	缺点：
   		1、占用服务端存储空间
2.未登录状态操作购物车

2.1.业务逻辑：

1、从cookie中查询商品列表：Map<itemId,TbItem> 商品购买数量使用TbItem的num保存

	    购物车已存在则直接返回

        购物车不存在则创建空的购物车并返回

2、添加商品到购物车：

	如果购物车存在该商品，商品数量相加。

	如果购物车不存在该商品，根据商品id查询商品信息并添加到购车列表

3、把购车商品列表写入cookie。

	读写cookie可以使用CookieUtils工具类实现
2020-06-16
1.1.订单功能

1、在购物车页面点击“去结算”按钮跳转到订单确认页面

	a) 展示商品列表

	b) 配送地址列表

    c) 选择支付方式

2、订单确认页面需要根据用户查询配送地址，展示订单确认页面之前，应该确认用户身份

	a) 如果用户未登录或登录过期跳转到登录页面

	d) 登录成功后再跳转到订单确认页面

3、提交订单

	a) 生成订单

4、扣减库存

5、关闭超时订单

	a) 定时扫描超时2天未付款的订单，并关闭订单

	b) 加回库存
2.用户身份认证

在展示订单确认页面之前，需要对用户身份进行认证，要求用户必须登录。

2.1.功能分析

1、使用springmvc的拦截器拦截所有订单的请求

2、业务逻辑

	a)  从cookie中取token。

	b) 根据token调用sso服务查询用户信息。

	d) 如果查不到用户信息则跳转到登录页面。

	e) 查询到用户信息放行。
3.展示订单确认页面

3.1.功能分析

1、在购物车页面点击“去结算”按钮跳转到订单确认页面。

2、请求的url：/frontend/order/goSettlement

3、参数：ids，userId，token

4、查询redis中的购物车数据并返回给前端

5、配送地址列表，需要用户登录。需要根据用户id查询收货地址列表。静态数据。

6、支付方式。静态数据。






